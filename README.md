# DialogueAct-Prediction

## 何をしている
+ 応答の対話行為推定の精度/多様性(予測率)の向上を目指している
  + データセットの偏り問題を解消する
+ 背景
  + 現状の対話行為推定モデルは、不均衡性が強い(タグによってばらつき大きい)データに対して、多数派タグの予測しか行えない
  + タグによる偏りによって出現しにくいタグが出てきてしまい、対話の多様性が失われてしまう => 様々な内容(対話行為タグ)が予測できない
+ 目的
  + タグの誤りによって損失値を変動させる事で、少数派タグ(再現率/F値が低いタグ)の予測を行えるようにする
+ 現状
  + p: 0.2329046920505991 | r: 0.19271633318070341 | f: 0.18694432602374084 | acc: 0.5797840431913617

## Cost Sensitive loss とは
+ 通常の分類問題は、データ不均衡なものを扱って行われる
  + 学習器は、過半数を占めるクラスを少数派のクラスよりも重要視する => 正解率の向上が大事であるため

### 従来の損失関数の問題
+ 従来の損失関数は、予測正解率を上げる事を目的としているため、予測されやすいタグ(タグ数が多い)ものがよく正解しやすいという傾向が見られる
+ しかし、それだと対話における多様性(様々な内容の発話)が見られないという問題が発生する


### Affinity loss
+ データサンプリングの問題点
  + Oversampling
    + オーバーフィッティングや冗長性の影響を受けやす
    + Data Augmentationすれば、そこそこ精度良くなる
      + SMOTE => サンプリングアルゴリズム
  + Undersampling
    + 致命的な情報損失を受けやすい
+ ソフトマックスの問題
  + マージン最大化のアプローチを組み込めない
    + Softmaxを使うと使用できない
  + 分類空間上での各クラスが等間隔に配置されていない
    + 似ているものが近づくが、実際はクラスの大きさが大きく空間を占めてしまう
  + クラスによる長さの違い
    + 少数派クラスは、多数派クラスに比べ占めるベクトル空間が小さい
+ Affinity Lossの特徴
  + 各クラスの特徴量空間上のマージンを最大化する損失関数
  + 分類におけるデータ数不均衡を是正する正則化項
```math
L = L_{mm} + R(w)
```
**マージンの最大化の働くを持つ損失関数**
```math
d(f_{i}, w_{j}) = \exp(- \frac{(|f_{i} - w_{j}|)^2}{\sigma}) -(1) \\
L_{mm} = \sum_{j} max(0, \lambda + d(f_{i}, w_{j}) - d(f_{i}, w_{y_{i}})) -(2)
```
(1)は、あるデータiのクラスjとの類似度指標
```math
d(f_{i}, w_{j}) => 異なるクラス間の類似度 \\
d(f_{i}, w_{y_{i}}) => 同じクラス間の類似度
```
つまり、同じクラスがより1に近づくように、異なるクラスが0に近づくように


**分類領域を均一にする正則化項**
```math
R(w) = E[(|w_{j}-w_{k}|^2-\mu^{2})], s.t.j<k \\
\mu = \frac{2}{c^{2}-c} \sum_{j<k}|w_{j} - w_{k}|^2
```
データの各クラスサイズの不均衡を解決するため、
C: クラス数,
μ: 各クラスの重心間の距離の平均/バラつきの平均


### Cost Sensitive Cross Entoropy loss
+ 陰性と陽性に異なるペナルティ係数をつけて学習
+ 通常の分類損失に正則化の役割を果たす項を追加し、特定の等級から離れた場合に大きな**ペナルティ**を課す
+ 損失関数式
  + 通常の損失関数をベースとし、CS正則化項
  + CS正則化項では
    + 予測==正解の場合、nullコスト(実質0)とし、
    + 予測!=正解の場合、距離|予測-正解|によってコストを増大させる
    + ラベル依存のペナルティを実現
      + 正解の行と予測のスカラー値の積を計算
    + コスト行列では、アノテーションの信頼性について考慮しなければならない
      + ラベルが信頼できるものであれば、誤った予測にペナルティを課したいが、関連するラベルが信頼できないことがわかっていれば、誤った予測にも寛容になる


# 9/24
## Affinity Loss
+ 現在実行中 
+ 
## 提案手法
### コスト値をTF-IDF化化
+ 文章中に出てくる単語がどれだけ重要かを特徴ベクトルとして数値化
  + IDF: 多くの文章で出現する単語は重要でない
    + どの対話でも出てくる(多数派)対話行為を重要視しなくなる
```math
idf = \log (\frac{総対話数 or バッチ数}{対話行為xを含む対話数+1})
```
  + TF: ある文書で多く出現する単語は重要である
    + ある対話のみでしか出現しない(少数派)対話行為の重要度を上げる
```math
tf = \frac{対話系列における対話行為xの出現頻度}{対話系列長}
```

+ 仮説：各対話から出現頻度から対話行為タグの重要度を求め、重要度をコスト値にする事で、少数派タグでも予測できるようにする
+ 方法
  + 1, はじめの段階で、tfidfを用いたコスト行列を作成し学習を行う
    + 計算リソースの心配はないが、コスト行列が更新がないため学習する事での性能向上の期待ができない
  + 2, ミニバッチ毎にコスト行列を更新していく <=計算リソースが心配
    + 学習を行いながら更新を行うため、より最適なコスト値を求められる可能性がある


## 研究計画
9/24: affinity loss の実装
10/1: tfidfの提案
10/8: tfidfの実装案を図にまとめる
10/22: tfidfのモデルを構築・実行
10/29: Samplingの案をまとめる/論文の執筆を始める
11/12: Samplingの実装・ 実行/はじめに、関連研究、提案をまとめる
11/19: 論文ver1.0をまめる
11/26: 論文ver1.5に仕上げる
12/3: 論文ver2.0に仕上げ、提出


## データサンプリング


### Up sampling 


### Down sampling




## Usage
```
python3 train.py --expr [Model name]
```


## References